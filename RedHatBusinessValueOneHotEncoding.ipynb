{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuu/dev/anaconda3/envs/redhat/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>char_1</th>\n",
       "      <th>group_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>date</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>...</th>\n",
       "      <th>char_29</th>\n",
       "      <th>char_30</th>\n",
       "      <th>char_31</th>\n",
       "      <th>char_32</th>\n",
       "      <th>char_33</th>\n",
       "      <th>char_34</th>\n",
       "      <th>char_35</th>\n",
       "      <th>char_36</th>\n",
       "      <th>char_37</th>\n",
       "      <th>char_38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>type 2</td>\n",
       "      <td>group 17304</td>\n",
       "      <td>type 2</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 3</td>\n",
       "      <td>type 11</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100002</td>\n",
       "      <td>type 2</td>\n",
       "      <td>group 8688</td>\n",
       "      <td>type 3</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>type 28</td>\n",
       "      <td>type 9</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 3</td>\n",
       "      <td>type 11</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    people_id  char_1      group_1  char_2       date   char_3  char_4  \\\n",
       "0     ppl_100  type 2  group 17304  type 2 2021-06-29   type 5  type 5   \n",
       "1  ppl_100002  type 2   group 8688  type 3 2021-01-06  type 28  type 9   \n",
       "\n",
       "   char_5  char_6   char_7   ...   char_29 char_30 char_31 char_32 char_33  \\\n",
       "0  type 5  type 3  type 11   ...     False    True    True   False   False   \n",
       "1  type 5  type 3  type 11   ...     False    True    True    True    True   \n",
       "\n",
       "  char_34 char_35 char_36 char_37 char_38  \n",
       "0    True    True    True   False      36  \n",
       "1    True    True    True   False      76  \n",
       "\n",
       "[2 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = pd.read_csv(\"people.csv\", dtype={'people_id': np.str, 'activity_id': np.str, 'char_38': np.int32}, parse_dates=['date'])\n",
    "people[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>date</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>char_8</th>\n",
       "      <th>char_9</th>\n",
       "      <th>char_10</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_1734928</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>type 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_2434093</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  people_id   activity_id       date activity_category char_1 char_2 char_3  \\\n",
       "0   ppl_100  act2_1734928 2023-08-26            type 4    NaN    NaN    NaN   \n",
       "1   ppl_100  act2_2434093 2022-09-27            type 2    NaN    NaN    NaN   \n",
       "\n",
       "  char_4 char_5 char_6 char_7 char_8 char_9  char_10  outcome  \n",
       "0    NaN    NaN    NaN    NaN    NaN    NaN  type 76        0  \n",
       "1    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"act_train.csv\",dtype={'people_id': np.str, 'activity_id': np.str, 'outcome': np.int8}, parse_dates=['date'])\n",
    "train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>date</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>char_8</th>\n",
       "      <th>char_9</th>\n",
       "      <th>char_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100004</td>\n",
       "      <td>act1_249281</td>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 10</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 6</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 7</td>\n",
       "      <td>type 4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100004</td>\n",
       "      <td>act2_230855</td>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>type 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    people_id  activity_id       date activity_category  char_1   char_2  \\\n",
       "0  ppl_100004  act1_249281 2022-07-20            type 1  type 5  type 10   \n",
       "1  ppl_100004  act2_230855 2022-07-20            type 5     NaN      NaN   \n",
       "\n",
       "   char_3  char_4  char_5  char_6  char_7  char_8  char_9   char_10  \n",
       "0  type 5  type 1  type 6  type 1  type 1  type 7  type 4       NaN  \n",
       "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN  type 682  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"act_test.csv\",dtype={'people_id': np.str, 'activity_id': np.str}, parse_dates=['date'])\n",
    "test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (2197291, 15)\n",
      "Test data shape: (498687, 14)\n",
      "People data shape: (189118, 41)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape: \" + format(train.shape))\n",
    "print(\"Test data shape: \" + format(test.shape))\n",
    "print(\"People data shape: \" + format(people.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# people list the people number and their characteristics\n",
    "# act_train, act_test set list the train and test set respectively\n",
    "# we need to join the people with the train and test set so that\n",
    "# their characteristics are captured as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = train.merge(people, on='people_id', how='left', left_index=True)\n",
    "X_test  = test.merge(people, on='people_id', how='left', left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>date_x</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1_x</th>\n",
       "      <th>char_2_x</th>\n",
       "      <th>char_3_x</th>\n",
       "      <th>char_4_x</th>\n",
       "      <th>char_5_x</th>\n",
       "      <th>char_6_x</th>\n",
       "      <th>...</th>\n",
       "      <th>char_29</th>\n",
       "      <th>char_30</th>\n",
       "      <th>char_31</th>\n",
       "      <th>char_32</th>\n",
       "      <th>char_33</th>\n",
       "      <th>char_34</th>\n",
       "      <th>char_35</th>\n",
       "      <th>char_36</th>\n",
       "      <th>char_37</th>\n",
       "      <th>char_38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_1734928</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>type 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_2434093</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  people_id   activity_id     date_x activity_category char_1_x char_2_x  \\\n",
       "0   ppl_100  act2_1734928 2023-08-26            type 4      NaN      NaN   \n",
       "0   ppl_100  act2_2434093 2022-09-27            type 2      NaN      NaN   \n",
       "\n",
       "  char_3_x char_4_x char_5_x char_6_x   ...   char_29 char_30 char_31 char_32  \\\n",
       "0      NaN      NaN      NaN      NaN   ...     False    True    True   False   \n",
       "0      NaN      NaN      NaN      NaN   ...     False    True    True   False   \n",
       "\n",
       "   char_33 char_34 char_35 char_36 char_37 char_38  \n",
       "0    False    True    True    True   False      36  \n",
       "0    False    True    True    True   False      36  \n",
       "\n",
       "[2 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people_id',\n",
       " 'activity_id',\n",
       " 'date_x',\n",
       " 'activity_category',\n",
       " 'char_1_x',\n",
       " 'char_2_x',\n",
       " 'char_3_x',\n",
       " 'char_4_x',\n",
       " 'char_5_x',\n",
       " 'char_6_x',\n",
       " 'char_7_x',\n",
       " 'char_8_x',\n",
       " 'char_9_x',\n",
       " 'char_10_x',\n",
       " 'outcome',\n",
       " 'char_1_y',\n",
       " 'group_1',\n",
       " 'char_2_y',\n",
       " 'date_y',\n",
       " 'char_3_y',\n",
       " 'char_4_y',\n",
       " 'char_5_y',\n",
       " 'char_6_y',\n",
       " 'char_7_y',\n",
       " 'char_8_y',\n",
       " 'char_9_y',\n",
       " 'char_10_y',\n",
       " 'char_11',\n",
       " 'char_12',\n",
       " 'char_13',\n",
       " 'char_14',\n",
       " 'char_15',\n",
       " 'char_16',\n",
       " 'char_17',\n",
       " 'char_18',\n",
       " 'char_19',\n",
       " 'char_20',\n",
       " 'char_21',\n",
       " 'char_22',\n",
       " 'char_23',\n",
       " 'char_24',\n",
       " 'char_25',\n",
       " 'char_26',\n",
       " 'char_27',\n",
       " 'char_28',\n",
       " 'char_29',\n",
       " 'char_30',\n",
       " 'char_31',\n",
       " 'char_32',\n",
       " 'char_33',\n",
       " 'char_34',\n",
       " 'char_35',\n",
       " 'char_36',\n",
       " 'char_37',\n",
       " 'char_38']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2197291, 55)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# outcome is the y value of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# char_10_y, char_11 => char_37 are boolean\n",
    "# char_38 are numerical => no need to do anything\n",
    "# char_1_y => char_9_y are categorical => do a one-hot encoding to get sparse matrix\n",
    "# char_1_x => char_10_x are categorical => do a one-hot encoding to get sparse matrix\n",
    "# group_1 is categorical\n",
    "# date_x is the activity date, date_y is possibly the user registration date.\n",
    "# activity_categorical is categorical\n",
    "# people_id and activity_id will not contribute to the decision => can be used as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['char_10_y',\n",
       " 'char_11',\n",
       " 'char_12',\n",
       " 'char_13',\n",
       " 'char_14',\n",
       " 'char_15',\n",
       " 'char_16',\n",
       " 'char_17',\n",
       " 'char_18',\n",
       " 'char_19',\n",
       " 'char_20',\n",
       " 'char_21',\n",
       " 'char_22',\n",
       " 'char_23',\n",
       " 'char_24',\n",
       " 'char_25',\n",
       " 'char_26',\n",
       " 'char_27',\n",
       " 'char_28',\n",
       " 'char_29',\n",
       " 'char_30',\n",
       " 'char_31',\n",
       " 'char_32',\n",
       " 'char_33',\n",
       " 'char_34',\n",
       " 'char_35',\n",
       " 'char_36',\n",
       " 'char_37']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_separately = ['people_id', 'activity_id', 'date_x', 'date_y', 'outcome', 'char_38']\n",
    "categorical = ['char_1_y', 'char_2_y', 'char_3_y', 'char_4_y', 'char_5_y',\n",
    "               'char_6_y', 'char_7_y', 'char_8_y', 'char_9_y',\n",
    "               'char_1_x', 'char_2_x', 'char_3_x', 'char_4_x', 'char_5_x',\n",
    "               'char_6_x', 'char_7_x', 'char_8_x', 'char_9_x', 'char_10_x',\n",
    "               'group_1', 'activity_category']\n",
    "not_categorical = [x for x in X_train.columns if x not in categorical \\\n",
    "                   and x not in used_separately]\n",
    "not_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessing(dataset):\n",
    "    local_data = dataset\n",
    "    \n",
    "    for col in list(local_data.columns):\n",
    "        # fill the categorical NA with type 0,\n",
    "        # for each categorical col, we only take the number, and convert to int32\n",
    "        if col in categorical:\n",
    "            local_data[col].fillna('type 0', inplace=True)\n",
    "            local_data[col] = local_data[col].apply(\n",
    "                lambda x: x.split(' ')[1]).astype(np.int32)\n",
    "\n",
    "        if col in not_categorical:\n",
    "            # boolean values are converted to int aswell\n",
    "            local_data[col] = local_data[col].astype(np.int8)\n",
    "        # this doesnot deal with date time data\n",
    "    \n",
    "    # date_x is the activity date, date_y is possibly the reg date.\n",
    "    local_data['year_x'] = local_data['date_x'].dt.year\n",
    "    local_data['month_x'] = local_data['date_x'].dt.month\n",
    "    local_data['day_x'] = local_data['date_x'].dt.day\n",
    "    local_data['isweekend_x'] = (local_data['date_x'].dt.weekday >= 5).astype(int)\n",
    "    # drop date_x after splitting its features\n",
    "    local_data = local_data.drop('date_x', axis = 1)\n",
    "    # we may not need date_y as its only reg date\n",
    "    local_data = local_data.drop('date_y', axis = 1)\n",
    "    return local_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = preprocessing(X_train)\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=X_train.sort_values(['people_id'], ascending=[1])\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = preprocessing(X_test)\n",
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test=X_test.sort_values(['people_id'], ascending=[1])\n",
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = X_train.outcome\n",
    "X_train=X_train.drop('outcome',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we need to take care of categorial data using one-hot-encoding.\n",
    "# but the number of dimension resulted using one-hot-ending will equal the max number \n",
    "# in the categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# thus we need to reduce the number of dimension by checking only those numbers that\n",
    "# appear in either train or test set.\n",
    "\n",
    "# the following is a cheat because we're not supposed to use the data from the \n",
    "# test set for the preprocessing of the training set\n",
    "\n",
    "# join the two set so the one hot encoding will have all the values for each categorical\n",
    "# column\n",
    "All = pd.concat([X_train, X_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "All[categorical][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then fit the one hot encoding using both sets\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc=enc.fit(All[categorical])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_ohe=enc.transform(X_train[categorical])\n",
    "X_train_ohe[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_ohe=enc.transform(X_test[categorical])\n",
    "X_test_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_categorical.extend(['char_38', 'year_x',\n",
    "       'month_x', 'day_x', 'isweekend_x'])\n",
    "not_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "All.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_all=hstack((X_train[not_categorical], X_train_ohe))\n",
    "X_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_all=hstack((X_test[not_categorical], X_test_ohe))\n",
    "X_test_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Training data: \" + format(X_train_all.shape))\n",
    "print(\"Test data: \" + format(X_test_all.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.89192\n",
      "Will train until train-auc hasn't improved in 20 rounds.\n",
      "[1]\ttrain-auc:0.900562\n",
      "[2]\ttrain-auc:0.909177\n",
      "[3]\ttrain-auc:0.917468\n",
      "[4]\ttrain-auc:0.925206\n",
      "[5]\ttrain-auc:0.932294\n",
      "[6]\ttrain-auc:0.938923\n",
      "[7]\ttrain-auc:0.945178\n",
      "[8]\ttrain-auc:0.951067\n",
      "[9]\ttrain-auc:0.956569\n",
      "[10]\ttrain-auc:0.961622\n",
      "[11]\ttrain-auc:0.966171\n",
      "[12]\ttrain-auc:0.970196\n",
      "[13]\ttrain-auc:0.973708\n",
      "[14]\ttrain-auc:0.976735\n",
      "[15]\ttrain-auc:0.979315\n",
      "[16]\ttrain-auc:0.981501\n",
      "[17]\ttrain-auc:0.983343\n",
      "[18]\ttrain-auc:0.984893\n",
      "[19]\ttrain-auc:0.986192\n",
      "[20]\ttrain-auc:0.987287\n",
      "[21]\ttrain-auc:0.988213\n",
      "[22]\ttrain-auc:0.989003\n",
      "[23]\ttrain-auc:0.989683\n",
      "[24]\ttrain-auc:0.990276\n",
      "[25]\ttrain-auc:0.990798\n",
      "[26]\ttrain-auc:0.991263\n",
      "[27]\ttrain-auc:0.991677\n",
      "[28]\ttrain-auc:0.99205\n",
      "[29]\ttrain-auc:0.992387\n",
      "[30]\ttrain-auc:0.992694\n",
      "[31]\ttrain-auc:0.992975\n",
      "[32]\ttrain-auc:0.993234\n",
      "[33]\ttrain-auc:0.993471\n",
      "[34]\ttrain-auc:0.99369\n",
      "[35]\ttrain-auc:0.993892\n",
      "[36]\ttrain-auc:0.994079\n",
      "[37]\ttrain-auc:0.994254\n",
      "[38]\ttrain-auc:0.994416\n",
      "[39]\ttrain-auc:0.994568\n",
      "[40]\ttrain-auc:0.99471\n",
      "[41]\ttrain-auc:0.994843\n",
      "[42]\ttrain-auc:0.994968\n",
      "[43]\ttrain-auc:0.995086\n",
      "[44]\ttrain-auc:0.995197\n",
      "[45]\ttrain-auc:0.995302\n",
      "[46]\ttrain-auc:0.995401\n",
      "[47]\ttrain-auc:0.995494\n",
      "[48]\ttrain-auc:0.995582\n",
      "[49]\ttrain-auc:0.995666\n",
      "[50]\ttrain-auc:0.995746\n",
      "[51]\ttrain-auc:0.995821\n",
      "[52]\ttrain-auc:0.995893\n",
      "[53]\ttrain-auc:0.995961\n",
      "[54]\ttrain-auc:0.996026\n",
      "[55]\ttrain-auc:0.996087\n",
      "[56]\ttrain-auc:0.996146\n",
      "[57]\ttrain-auc:0.996201\n",
      "[58]\ttrain-auc:0.996254\n",
      "[59]\ttrain-auc:0.996305\n",
      "[60]\ttrain-auc:0.996353\n",
      "[61]\ttrain-auc:0.996399\n",
      "[62]\ttrain-auc:0.996443\n",
      "[63]\ttrain-auc:0.996485\n",
      "[64]\ttrain-auc:0.996525\n",
      "[65]\ttrain-auc:0.996563\n",
      "[66]\ttrain-auc:0.9966\n",
      "[67]\ttrain-auc:0.996635\n",
      "[68]\ttrain-auc:0.996668\n",
      "[69]\ttrain-auc:0.996701\n",
      "[70]\ttrain-auc:0.996731\n",
      "[71]\ttrain-auc:0.996761\n",
      "[72]\ttrain-auc:0.996789\n",
      "[73]\ttrain-auc:0.996816\n",
      "[74]\ttrain-auc:0.996842\n",
      "[75]\ttrain-auc:0.996867\n",
      "[76]\ttrain-auc:0.996891\n",
      "[77]\ttrain-auc:0.996914\n",
      "[78]\ttrain-auc:0.996936\n",
      "[79]\ttrain-auc:0.996957\n",
      "[80]\ttrain-auc:0.996977\n",
      "[81]\ttrain-auc:0.996997\n",
      "[82]\ttrain-auc:0.997015\n",
      "[83]\ttrain-auc:0.997033\n",
      "[84]\ttrain-auc:0.99705\n",
      "[85]\ttrain-auc:0.997067\n",
      "[86]\ttrain-auc:0.997083\n",
      "[87]\ttrain-auc:0.997098\n",
      "[88]\ttrain-auc:0.997113\n",
      "[89]\ttrain-auc:0.997127\n",
      "[90]\ttrain-auc:0.99714\n",
      "[91]\ttrain-auc:0.997154\n",
      "[92]\ttrain-auc:0.997166\n",
      "[93]\ttrain-auc:0.997178\n",
      "[94]\ttrain-auc:0.99719\n",
      "[95]\ttrain-auc:0.997201\n",
      "[96]\ttrain-auc:0.997211\n",
      "[97]\ttrain-auc:0.997222\n",
      "[98]\ttrain-auc:0.997231\n",
      "[99]\ttrain-auc:0.997241\n",
      "[100]\ttrain-auc:0.99725\n",
      "[101]\ttrain-auc:0.997259\n",
      "[102]\ttrain-auc:0.997268\n",
      "[103]\ttrain-auc:0.997276\n",
      "[104]\ttrain-auc:0.997284\n",
      "[105]\ttrain-auc:0.997292\n",
      "[106]\ttrain-auc:0.997299\n",
      "[107]\ttrain-auc:0.997306\n",
      "[108]\ttrain-auc:0.997313\n",
      "[109]\ttrain-auc:0.99732\n",
      "[110]\ttrain-auc:0.997327\n",
      "[111]\ttrain-auc:0.997333\n",
      "[112]\ttrain-auc:0.997339\n",
      "[113]\ttrain-auc:0.997345\n",
      "[114]\ttrain-auc:0.997351\n",
      "[115]\ttrain-auc:0.997356\n",
      "[116]\ttrain-auc:0.997362\n",
      "[117]\ttrain-auc:0.997367\n",
      "[118]\ttrain-auc:0.997372\n",
      "[119]\ttrain-auc:0.997377\n",
      "[120]\ttrain-auc:0.997382\n",
      "[121]\ttrain-auc:0.997387\n",
      "[122]\ttrain-auc:0.997392\n",
      "[123]\ttrain-auc:0.997396\n",
      "[124]\ttrain-auc:0.997401\n",
      "[125]\ttrain-auc:0.997405\n",
      "[126]\ttrain-auc:0.997409\n",
      "[127]\ttrain-auc:0.997413\n",
      "[128]\ttrain-auc:0.997417\n",
      "[129]\ttrain-auc:0.997421\n",
      "[130]\ttrain-auc:0.997425\n",
      "[131]\ttrain-auc:0.997429\n",
      "[132]\ttrain-auc:0.997432\n",
      "[133]\ttrain-auc:0.997436\n",
      "[134]\ttrain-auc:0.997439\n",
      "[135]\ttrain-auc:0.997443\n",
      "[136]\ttrain-auc:0.997446\n",
      "[137]\ttrain-auc:0.997449\n",
      "[138]\ttrain-auc:0.997453\n",
      "[139]\ttrain-auc:0.997456\n",
      "[140]\ttrain-auc:0.997459\n",
      "[141]\ttrain-auc:0.997462\n",
      "[142]\ttrain-auc:0.997465\n",
      "[143]\ttrain-auc:0.997468\n",
      "[144]\ttrain-auc:0.99747\n",
      "[145]\ttrain-auc:0.997473\n",
      "[146]\ttrain-auc:0.997476\n",
      "[147]\ttrain-auc:0.997478\n",
      "[148]\ttrain-auc:0.997481\n",
      "[149]\ttrain-auc:0.997484\n",
      "[150]\ttrain-auc:0.997486\n",
      "[151]\ttrain-auc:0.997489\n",
      "[152]\ttrain-auc:0.997491\n",
      "[153]\ttrain-auc:0.997493\n",
      "[154]\ttrain-auc:0.997496\n",
      "[155]\ttrain-auc:0.997498\n",
      "[156]\ttrain-auc:0.9975\n",
      "[157]\ttrain-auc:0.997502\n",
      "[158]\ttrain-auc:0.997504\n",
      "[159]\ttrain-auc:0.997506\n",
      "[160]\ttrain-auc:0.997508\n",
      "[161]\ttrain-auc:0.99751\n",
      "[162]\ttrain-auc:0.997512\n",
      "[163]\ttrain-auc:0.997514\n",
      "[164]\ttrain-auc:0.997516\n",
      "[165]\ttrain-auc:0.997518\n",
      "[166]\ttrain-auc:0.99752\n",
      "[167]\ttrain-auc:0.997522\n",
      "[168]\ttrain-auc:0.997523\n",
      "[169]\ttrain-auc:0.997525\n",
      "[170]\ttrain-auc:0.997527\n",
      "[171]\ttrain-auc:0.997528\n",
      "[172]\ttrain-auc:0.99753\n",
      "[173]\ttrain-auc:0.997532\n",
      "[174]\ttrain-auc:0.997533\n",
      "[175]\ttrain-auc:0.997535\n",
      "[176]\ttrain-auc:0.997536\n",
      "[177]\ttrain-auc:0.997538\n",
      "[178]\ttrain-auc:0.997539\n",
      "[179]\ttrain-auc:0.997541\n",
      "[180]\ttrain-auc:0.997542\n",
      "[181]\ttrain-auc:0.997543\n",
      "[182]\ttrain-auc:0.997545\n",
      "[183]\ttrain-auc:0.997546\n",
      "[184]\ttrain-auc:0.997547\n",
      "[185]\ttrain-auc:0.997549\n",
      "[186]\ttrain-auc:0.99755\n",
      "[187]\ttrain-auc:0.997551\n",
      "[188]\ttrain-auc:0.997553\n",
      "[189]\ttrain-auc:0.997554\n",
      "[190]\ttrain-auc:0.997555\n",
      "[191]\ttrain-auc:0.997556\n",
      "[192]\ttrain-auc:0.997557\n",
      "[193]\ttrain-auc:0.997558\n",
      "[194]\ttrain-auc:0.99756\n",
      "[195]\ttrain-auc:0.997561\n",
      "[196]\ttrain-auc:0.997562\n",
      "[197]\ttrain-auc:0.997563\n",
      "[198]\ttrain-auc:0.997564\n",
      "[199]\ttrain-auc:0.997565\n",
      "[200]\ttrain-auc:0.997566\n",
      "[201]\ttrain-auc:0.997567\n",
      "[202]\ttrain-auc:0.997568\n",
      "[203]\ttrain-auc:0.997569\n",
      "[204]\ttrain-auc:0.99757\n",
      "[205]\ttrain-auc:0.997571\n",
      "[206]\ttrain-auc:0.997572\n",
      "[207]\ttrain-auc:0.997573\n",
      "[208]\ttrain-auc:0.997574\n",
      "[209]\ttrain-auc:0.997575\n",
      "[210]\ttrain-auc:0.997576\n",
      "[211]\ttrain-auc:0.997576\n",
      "[212]\ttrain-auc:0.997577\n",
      "[213]\ttrain-auc:0.997578\n",
      "[214]\ttrain-auc:0.997579\n",
      "[215]\ttrain-auc:0.99758\n",
      "[216]\ttrain-auc:0.997581\n",
      "[217]\ttrain-auc:0.997582\n",
      "[218]\ttrain-auc:0.997582\n",
      "[219]\ttrain-auc:0.997583\n",
      "[220]\ttrain-auc:0.997584\n",
      "[221]\ttrain-auc:0.997585\n",
      "[222]\ttrain-auc:0.997586\n",
      "[223]\ttrain-auc:0.997586\n",
      "[224]\ttrain-auc:0.997587\n",
      "[225]\ttrain-auc:0.997588\n",
      "[226]\ttrain-auc:0.997589\n",
      "[227]\ttrain-auc:0.997589\n",
      "[228]\ttrain-auc:0.99759\n",
      "[229]\ttrain-auc:0.997591\n",
      "[230]\ttrain-auc:0.997591\n",
      "[231]\ttrain-auc:0.997592\n",
      "[232]\ttrain-auc:0.997593\n",
      "[233]\ttrain-auc:0.997594\n",
      "[234]\ttrain-auc:0.997594\n",
      "[235]\ttrain-auc:0.997595\n",
      "[236]\ttrain-auc:0.997595\n",
      "[237]\ttrain-auc:0.997596\n",
      "[238]\ttrain-auc:0.997597\n",
      "[239]\ttrain-auc:0.997597\n",
      "[240]\ttrain-auc:0.997598\n",
      "[241]\ttrain-auc:0.997599\n",
      "[242]\ttrain-auc:0.997599\n",
      "[243]\ttrain-auc:0.9976\n",
      "[244]\ttrain-auc:0.997601\n",
      "[245]\ttrain-auc:0.997601\n",
      "[246]\ttrain-auc:0.997602\n",
      "[247]\ttrain-auc:0.997602\n",
      "[248]\ttrain-auc:0.997603\n",
      "[249]\ttrain-auc:0.997604\n",
      "[250]\ttrain-auc:0.997604\n",
      "[251]\ttrain-auc:0.997605\n",
      "[252]\ttrain-auc:0.997605\n",
      "[253]\ttrain-auc:0.997606\n",
      "[254]\ttrain-auc:0.997606\n",
      "[255]\ttrain-auc:0.997607\n",
      "[256]\ttrain-auc:0.997607\n",
      "[257]\ttrain-auc:0.997608\n",
      "[258]\ttrain-auc:0.997608\n",
      "[259]\ttrain-auc:0.997609\n",
      "[260]\ttrain-auc:0.997609\n",
      "[261]\ttrain-auc:0.99761\n",
      "[262]\ttrain-auc:0.99761\n",
      "[263]\ttrain-auc:0.997611\n",
      "[264]\ttrain-auc:0.997611\n",
      "[265]\ttrain-auc:0.997612\n",
      "[266]\ttrain-auc:0.997612\n",
      "[267]\ttrain-auc:0.997613\n",
      "[268]\ttrain-auc:0.997613\n",
      "[269]\ttrain-auc:0.997614\n",
      "[270]\ttrain-auc:0.997614\n",
      "[271]\ttrain-auc:0.997615\n",
      "[272]\ttrain-auc:0.997615\n",
      "[273]\ttrain-auc:0.997616\n",
      "[274]\ttrain-auc:0.997616\n",
      "[275]\ttrain-auc:0.997616\n",
      "[276]\ttrain-auc:0.997617\n",
      "[277]\ttrain-auc:0.997617\n",
      "[278]\ttrain-auc:0.997618\n",
      "[279]\ttrain-auc:0.997618\n",
      "[280]\ttrain-auc:0.997619\n",
      "[281]\ttrain-auc:0.997619\n",
      "[282]\ttrain-auc:0.997619\n",
      "[283]\ttrain-auc:0.99762\n",
      "[284]\ttrain-auc:0.99762\n",
      "[285]\ttrain-auc:0.997621\n",
      "[286]\ttrain-auc:0.997621\n",
      "[287]\ttrain-auc:0.997621\n",
      "[288]\ttrain-auc:0.997622\n",
      "[289]\ttrain-auc:0.997622\n",
      "[290]\ttrain-auc:0.997622\n",
      "[291]\ttrain-auc:0.997623\n",
      "[292]\ttrain-auc:0.997623\n",
      "[293]\ttrain-auc:0.997624\n",
      "[294]\ttrain-auc:0.997624\n",
      "[295]\ttrain-auc:0.997624\n",
      "[296]\ttrain-auc:0.997625\n",
      "[297]\ttrain-auc:0.997625\n",
      "[298]\ttrain-auc:0.997625\n",
      "[299]\ttrain-auc:0.997626\n",
      "[300]\ttrain-auc:0.997626\n",
      "[301]\ttrain-auc:0.997626\n",
      "[302]\ttrain-auc:0.997627\n",
      "[303]\ttrain-auc:0.997627\n",
      "[304]\ttrain-auc:0.997627\n",
      "[305]\ttrain-auc:0.997628\n",
      "[306]\ttrain-auc:0.997628\n",
      "[307]\ttrain-auc:0.997628\n",
      "[308]\ttrain-auc:0.997629\n",
      "[309]\ttrain-auc:0.997629\n",
      "[310]\ttrain-auc:0.997629\n",
      "[311]\ttrain-auc:0.997629\n",
      "[312]\ttrain-auc:0.99763\n",
      "[313]\ttrain-auc:0.99763\n",
      "[314]\ttrain-auc:0.99763\n",
      "[315]\ttrain-auc:0.997631\n",
      "[316]\ttrain-auc:0.997631\n",
      "[317]\ttrain-auc:0.997631\n",
      "[318]\ttrain-auc:0.997631\n",
      "[319]\ttrain-auc:0.997632\n",
      "[320]\ttrain-auc:0.997632\n",
      "[321]\ttrain-auc:0.997632\n",
      "[322]\ttrain-auc:0.997633\n",
      "[323]\ttrain-auc:0.997633\n",
      "[324]\ttrain-auc:0.997633\n",
      "[325]\ttrain-auc:0.997633\n",
      "[326]\ttrain-auc:0.997634\n",
      "[327]\ttrain-auc:0.997634\n",
      "[328]\ttrain-auc:0.997634\n",
      "[329]\ttrain-auc:0.997634\n",
      "[330]\ttrain-auc:0.997635\n",
      "[331]\ttrain-auc:0.997635\n",
      "[332]\ttrain-auc:0.997635\n",
      "[333]\ttrain-auc:0.997635\n",
      "[334]\ttrain-auc:0.997636\n",
      "[335]\ttrain-auc:0.997636\n",
      "[336]\ttrain-auc:0.997636\n",
      "[337]\ttrain-auc:0.997636\n",
      "[338]\ttrain-auc:0.997637\n",
      "[339]\ttrain-auc:0.997637\n",
      "[340]\ttrain-auc:0.997637\n",
      "[341]\ttrain-auc:0.997637\n",
      "[342]\ttrain-auc:0.997637\n",
      "[343]\ttrain-auc:0.997638\n",
      "[344]\ttrain-auc:0.997638\n",
      "[345]\ttrain-auc:0.997638\n",
      "[346]\ttrain-auc:0.997638\n",
      "[347]\ttrain-auc:0.997639\n",
      "[348]\ttrain-auc:0.997639\n",
      "[349]\ttrain-auc:0.997639\n",
      "[350]\ttrain-auc:0.997639\n",
      "[351]\ttrain-auc:0.997639\n",
      "[352]\ttrain-auc:0.99764\n",
      "[353]\ttrain-auc:0.99764\n",
      "[354]\ttrain-auc:0.99764\n",
      "[355]\ttrain-auc:0.99764\n",
      "[356]\ttrain-auc:0.99764\n",
      "[357]\ttrain-auc:0.99764\n",
      "[358]\ttrain-auc:0.997641\n",
      "[359]\ttrain-auc:0.997641\n",
      "[360]\ttrain-auc:0.997641\n",
      "[361]\ttrain-auc:0.997641\n",
      "[362]\ttrain-auc:0.997641\n",
      "[363]\ttrain-auc:0.997642\n",
      "[364]\ttrain-auc:0.997642\n",
      "[365]\ttrain-auc:0.997642\n",
      "[366]\ttrain-auc:0.997642\n",
      "[367]\ttrain-auc:0.997642\n",
      "[368]\ttrain-auc:0.997643\n",
      "[369]\ttrain-auc:0.997643\n",
      "[370]\ttrain-auc:0.997643\n",
      "[371]\ttrain-auc:0.997643\n",
      "[372]\ttrain-auc:0.997643\n",
      "[373]\ttrain-auc:0.997643\n",
      "[374]\ttrain-auc:0.997644\n",
      "[375]\ttrain-auc:0.997644\n",
      "[376]\ttrain-auc:0.997644\n",
      "[377]\ttrain-auc:0.997644\n",
      "[378]\ttrain-auc:0.997644\n",
      "[379]\ttrain-auc:0.997644\n",
      "[380]\ttrain-auc:0.997644\n",
      "[381]\ttrain-auc:0.997645\n",
      "[382]\ttrain-auc:0.997645\n",
      "[383]\ttrain-auc:0.997645\n",
      "[384]\ttrain-auc:0.997645\n",
      "[385]\ttrain-auc:0.997645\n",
      "[386]\ttrain-auc:0.997645\n",
      "[387]\ttrain-auc:0.997645\n",
      "[388]\ttrain-auc:0.997646\n",
      "[389]\ttrain-auc:0.997646\n",
      "[390]\ttrain-auc:0.997646\n",
      "[391]\ttrain-auc:0.997646\n",
      "[392]\ttrain-auc:0.997646\n",
      "[393]\ttrain-auc:0.997646\n",
      "[394]\ttrain-auc:0.997646\n",
      "[395]\ttrain-auc:0.997647\n",
      "[396]\ttrain-auc:0.997647\n",
      "[397]\ttrain-auc:0.997647\n",
      "[398]\ttrain-auc:0.997647\n",
      "[399]\ttrain-auc:0.997647\n",
      "[400]\ttrain-auc:0.997647\n",
      "[401]\ttrain-auc:0.997647\n",
      "[402]\ttrain-auc:0.997648\n",
      "[403]\ttrain-auc:0.997648\n",
      "[404]\ttrain-auc:0.997648\n",
      "[405]\ttrain-auc:0.997648\n",
      "[406]\ttrain-auc:0.997648\n",
      "[407]\ttrain-auc:0.997648\n",
      "[408]\ttrain-auc:0.997648\n",
      "[409]\ttrain-auc:0.997648\n",
      "[410]\ttrain-auc:0.997648\n",
      "[411]\ttrain-auc:0.997649\n",
      "[412]\ttrain-auc:0.997649\n",
      "[413]\ttrain-auc:0.997649\n",
      "[414]\ttrain-auc:0.997649\n",
      "[415]\ttrain-auc:0.997649\n",
      "[416]\ttrain-auc:0.997649\n",
      "[417]\ttrain-auc:0.997649\n",
      "[418]\ttrain-auc:0.997649\n",
      "[419]\ttrain-auc:0.997649\n",
      "[420]\ttrain-auc:0.99765\n",
      "[421]\ttrain-auc:0.99765\n",
      "[422]\ttrain-auc:0.99765\n",
      "[423]\ttrain-auc:0.99765\n",
      "[424]\ttrain-auc:0.99765\n",
      "[425]\ttrain-auc:0.99765\n",
      "[426]\ttrain-auc:0.99765\n",
      "[427]\ttrain-auc:0.99765\n",
      "[428]\ttrain-auc:0.99765\n",
      "[429]\ttrain-auc:0.99765\n",
      "[430]\ttrain-auc:0.997651\n",
      "[431]\ttrain-auc:0.997651\n",
      "[432]\ttrain-auc:0.997651\n",
      "[433]\ttrain-auc:0.997651\n",
      "[434]\ttrain-auc:0.997651\n",
      "[435]\ttrain-auc:0.997651\n",
      "[436]\ttrain-auc:0.997651\n",
      "[437]\ttrain-auc:0.997651\n",
      "[438]\ttrain-auc:0.997651\n",
      "[439]\ttrain-auc:0.997651\n",
      "[440]\ttrain-auc:0.997651\n",
      "[441]\ttrain-auc:0.997652\n",
      "[442]\ttrain-auc:0.997652\n",
      "[443]\ttrain-auc:0.997652\n",
      "[444]\ttrain-auc:0.997652\n",
      "[445]\ttrain-auc:0.997652\n",
      "[446]\ttrain-auc:0.997652\n",
      "[447]\ttrain-auc:0.997652\n",
      "[448]\ttrain-auc:0.997652\n",
      "[449]\ttrain-auc:0.997652\n",
      "[450]\ttrain-auc:0.997652\n",
      "[451]\ttrain-auc:0.997652\n",
      "[452]\ttrain-auc:0.997652\n",
      "[453]\ttrain-auc:0.997652\n",
      "[454]\ttrain-auc:0.997653\n",
      "[455]\ttrain-auc:0.997653\n",
      "[456]\ttrain-auc:0.997653\n",
      "[457]\ttrain-auc:0.997653\n",
      "[458]\ttrain-auc:0.997653\n",
      "[459]\ttrain-auc:0.997653\n",
      "[460]\ttrain-auc:0.997653\n",
      "[461]\ttrain-auc:0.997653\n",
      "[462]\ttrain-auc:0.997653\n",
      "[463]\ttrain-auc:0.997653\n",
      "[464]\ttrain-auc:0.997653\n",
      "[465]\ttrain-auc:0.997653\n",
      "[466]\ttrain-auc:0.997653\n",
      "[467]\ttrain-auc:0.997653\n",
      "[468]\ttrain-auc:0.997653\n",
      "[469]\ttrain-auc:0.997654\n",
      "[470]\ttrain-auc:0.997654\n",
      "[471]\ttrain-auc:0.997654\n",
      "[472]\ttrain-auc:0.997654\n",
      "[473]\ttrain-auc:0.997654\n",
      "[474]\ttrain-auc:0.997654\n",
      "[475]\ttrain-auc:0.997654\n",
      "[476]\ttrain-auc:0.997654\n",
      "[477]\ttrain-auc:0.997654\n",
      "[478]\ttrain-auc:0.997654\n",
      "[479]\ttrain-auc:0.997654\n",
      "[480]\ttrain-auc:0.997654\n",
      "[481]\ttrain-auc:0.997654\n",
      "[482]\ttrain-auc:0.997654\n",
      "[483]\ttrain-auc:0.997654\n",
      "[484]\ttrain-auc:0.997654\n",
      "[485]\ttrain-auc:0.997655\n",
      "[486]\ttrain-auc:0.997655\n",
      "[487]\ttrain-auc:0.997655\n",
      "[488]\ttrain-auc:0.997655\n",
      "[489]\ttrain-auc:0.997655\n",
      "[490]\ttrain-auc:0.997655\n",
      "[491]\ttrain-auc:0.997655\n",
      "[492]\ttrain-auc:0.997655\n",
      "[493]\ttrain-auc:0.997655\n",
      "[494]\ttrain-auc:0.997655\n",
      "[495]\ttrain-auc:0.997655\n",
      "[496]\ttrain-auc:0.997655\n",
      "[497]\ttrain-auc:0.997655\n",
      "[498]\ttrain-auc:0.997655\n",
      "[499]\ttrain-auc:0.997655\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train_all,label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_all)\n",
    "\n",
    "param = {'max_depth':10, 'eta':0.02, 'silent':1, 'objective':'binary:logistic',\n",
    "         'nthread':-1, 'eval_metric':'auc', 'subsample':0.7, 'colsample_bytree':0.7,\n",
    "         'min_child_weight':0, 'booster':\"gblinear\"}\n",
    "\n",
    "watchlist  = [(dtrain,'train')]\n",
    "num_round = 500\n",
    "early_stopping_rounds=20\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist ,early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "ypred_xgboost = bst.predict(dtest)\n",
    "output_xgboost = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred_xgboost })\n",
    "output_xgboost.to_csv('result_xgboost.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.924126\n",
      "Will train until train-auc hasn't improved in 10 rounds.\n",
      "[1]\ttrain-auc:0.947209\n",
      "[2]\ttrain-auc:0.95041\n",
      "[3]\ttrain-auc:0.952435\n",
      "[4]\ttrain-auc:0.954528\n",
      "[5]\ttrain-auc:0.956531\n",
      "[6]\ttrain-auc:0.958007\n",
      "[7]\ttrain-auc:0.959433\n",
      "[8]\ttrain-auc:0.960371\n",
      "[9]\ttrain-auc:0.960506\n",
      "[10]\ttrain-auc:0.961283\n",
      "[11]\ttrain-auc:0.961406\n",
      "[12]\ttrain-auc:0.962184\n",
      "[13]\ttrain-auc:0.96266\n",
      "[14]\ttrain-auc:0.962867\n",
      "[15]\ttrain-auc:0.963193\n",
      "[16]\ttrain-auc:0.963038\n",
      "[17]\ttrain-auc:0.963226\n",
      "[18]\ttrain-auc:0.964633\n",
      "[19]\ttrain-auc:0.964961\n",
      "[20]\ttrain-auc:0.96505\n",
      "[21]\ttrain-auc:0.965482\n",
      "[22]\ttrain-auc:0.965567\n",
      "[23]\ttrain-auc:0.965534\n",
      "[24]\ttrain-auc:0.965701\n",
      "[25]\ttrain-auc:0.966081\n",
      "[26]\ttrain-auc:0.96636\n",
      "[27]\ttrain-auc:0.967863\n",
      "[28]\ttrain-auc:0.968203\n",
      "[29]\ttrain-auc:0.968329\n",
      "[30]\ttrain-auc:0.968325\n",
      "[31]\ttrain-auc:0.968465\n",
      "[32]\ttrain-auc:0.968648\n",
      "[33]\ttrain-auc:0.968866\n",
      "[34]\ttrain-auc:0.969068\n",
      "[35]\ttrain-auc:0.969273\n",
      "[36]\ttrain-auc:0.969293\n",
      "[37]\ttrain-auc:0.969239\n",
      "[38]\ttrain-auc:0.969408\n",
      "[39]\ttrain-auc:0.969576\n",
      "[40]\ttrain-auc:0.96956\n",
      "[41]\ttrain-auc:0.969662\n",
      "[42]\ttrain-auc:0.969735\n",
      "[43]\ttrain-auc:0.970308\n",
      "[44]\ttrain-auc:0.970375\n",
      "[45]\ttrain-auc:0.970619\n",
      "[46]\ttrain-auc:0.970919\n",
      "[47]\ttrain-auc:0.971232\n",
      "[48]\ttrain-auc:0.971178\n",
      "[49]\ttrain-auc:0.971412\n",
      "[50]\ttrain-auc:0.971616\n",
      "[51]\ttrain-auc:0.971718\n",
      "[52]\ttrain-auc:0.971917\n",
      "[53]\ttrain-auc:0.972137\n",
      "[54]\ttrain-auc:0.972451\n",
      "[55]\ttrain-auc:0.97253\n",
      "[56]\ttrain-auc:0.972634\n",
      "[57]\ttrain-auc:0.9729\n",
      "[58]\ttrain-auc:0.972973\n",
      "[59]\ttrain-auc:0.973253\n",
      "[60]\ttrain-auc:0.973358\n",
      "[61]\ttrain-auc:0.973696\n",
      "[62]\ttrain-auc:0.973794\n",
      "[63]\ttrain-auc:0.973921\n",
      "[64]\ttrain-auc:0.973974\n",
      "[65]\ttrain-auc:0.974043\n",
      "[66]\ttrain-auc:0.974205\n",
      "[67]\ttrain-auc:0.974251\n",
      "[68]\ttrain-auc:0.974318\n",
      "[69]\ttrain-auc:0.974411\n",
      "[70]\ttrain-auc:0.974491\n",
      "[71]\ttrain-auc:0.974672\n",
      "[72]\ttrain-auc:0.974718\n",
      "[73]\ttrain-auc:0.974764\n",
      "[74]\ttrain-auc:0.975003\n",
      "[75]\ttrain-auc:0.975258\n",
      "[76]\ttrain-auc:0.975463\n",
      "[77]\ttrain-auc:0.975561\n",
      "[78]\ttrain-auc:0.975636\n",
      "[79]\ttrain-auc:0.975788\n",
      "[80]\ttrain-auc:0.97583\n",
      "[81]\ttrain-auc:0.975981\n",
      "[82]\ttrain-auc:0.976068\n",
      "[83]\ttrain-auc:0.976172\n",
      "[84]\ttrain-auc:0.976304\n",
      "[85]\ttrain-auc:0.976467\n",
      "[86]\ttrain-auc:0.97661\n",
      "[87]\ttrain-auc:0.976916\n",
      "[88]\ttrain-auc:0.977137\n",
      "[89]\ttrain-auc:0.977278\n",
      "[90]\ttrain-auc:0.977556\n",
      "[91]\ttrain-auc:0.977754\n",
      "[92]\ttrain-auc:0.977865\n",
      "[93]\ttrain-auc:0.977928\n",
      "[94]\ttrain-auc:0.978113\n",
      "[95]\ttrain-auc:0.978399\n",
      "[96]\ttrain-auc:0.978498\n",
      "[97]\ttrain-auc:0.97859\n",
      "[98]\ttrain-auc:0.978662\n",
      "[99]\ttrain-auc:0.978697\n",
      "[100]\ttrain-auc:0.978808\n",
      "[101]\ttrain-auc:0.978954\n",
      "[102]\ttrain-auc:0.979126\n",
      "[103]\ttrain-auc:0.979181\n",
      "[104]\ttrain-auc:0.979271\n",
      "[105]\ttrain-auc:0.979431\n",
      "[106]\ttrain-auc:0.979569\n",
      "[107]\ttrain-auc:0.97963\n",
      "[108]\ttrain-auc:0.979837\n",
      "[109]\ttrain-auc:0.980063\n",
      "[110]\ttrain-auc:0.980225\n",
      "[111]\ttrain-auc:0.980249\n",
      "[112]\ttrain-auc:0.980389\n",
      "[113]\ttrain-auc:0.980639\n",
      "[114]\ttrain-auc:0.980777\n",
      "[115]\ttrain-auc:0.980816\n",
      "[116]\ttrain-auc:0.980864\n",
      "[117]\ttrain-auc:0.980935\n",
      "[118]\ttrain-auc:0.980946\n",
      "[119]\ttrain-auc:0.981056\n",
      "[120]\ttrain-auc:0.981083\n",
      "[121]\ttrain-auc:0.981125\n",
      "[122]\ttrain-auc:0.981198\n",
      "[123]\ttrain-auc:0.981286\n",
      "[124]\ttrain-auc:0.981359\n",
      "[125]\ttrain-auc:0.981407\n",
      "[126]\ttrain-auc:0.981512\n",
      "[127]\ttrain-auc:0.981627\n",
      "[128]\ttrain-auc:0.98168\n",
      "[129]\ttrain-auc:0.981727\n",
      "[130]\ttrain-auc:0.981815\n",
      "[131]\ttrain-auc:0.981866\n",
      "[132]\ttrain-auc:0.981868\n",
      "[133]\ttrain-auc:0.981931\n",
      "[134]\ttrain-auc:0.98201\n",
      "[135]\ttrain-auc:0.98208\n",
      "[136]\ttrain-auc:0.982099\n",
      "[137]\ttrain-auc:0.982159\n",
      "[138]\ttrain-auc:0.982231\n",
      "[139]\ttrain-auc:0.98226\n",
      "[140]\ttrain-auc:0.982416\n",
      "[141]\ttrain-auc:0.982461\n",
      "[142]\ttrain-auc:0.982586\n",
      "[143]\ttrain-auc:0.982666\n",
      "[144]\ttrain-auc:0.982714\n",
      "[145]\ttrain-auc:0.98283\n",
      "[146]\ttrain-auc:0.982859\n",
      "[147]\ttrain-auc:0.982921\n",
      "[148]\ttrain-auc:0.982933\n",
      "[149]\ttrain-auc:0.982987\n",
      "[150]\ttrain-auc:0.98304\n",
      "[151]\ttrain-auc:0.983113\n",
      "[152]\ttrain-auc:0.983233\n",
      "[153]\ttrain-auc:0.983247\n",
      "[154]\ttrain-auc:0.983266\n",
      "[155]\ttrain-auc:0.983277\n",
      "[156]\ttrain-auc:0.983301\n",
      "[157]\ttrain-auc:0.983308\n",
      "[158]\ttrain-auc:0.983361\n",
      "[159]\ttrain-auc:0.983362\n",
      "[160]\ttrain-auc:0.983374\n",
      "[161]\ttrain-auc:0.983385\n",
      "[162]\ttrain-auc:0.98343\n",
      "[163]\ttrain-auc:0.983499\n",
      "[164]\ttrain-auc:0.98352\n",
      "[165]\ttrain-auc:0.983517\n",
      "[166]\ttrain-auc:0.983557\n",
      "[167]\ttrain-auc:0.983615\n",
      "[168]\ttrain-auc:0.983681\n",
      "[169]\ttrain-auc:0.983684\n",
      "[170]\ttrain-auc:0.983804\n",
      "[171]\ttrain-auc:0.983832\n",
      "[172]\ttrain-auc:0.983897\n",
      "[173]\ttrain-auc:0.983927\n",
      "[174]\ttrain-auc:0.983981\n",
      "[175]\ttrain-auc:0.984\n",
      "[176]\ttrain-auc:0.984007\n",
      "[177]\ttrain-auc:0.984088\n",
      "[178]\ttrain-auc:0.984093\n",
      "[179]\ttrain-auc:0.984112\n",
      "[180]\ttrain-auc:0.984159\n",
      "[181]\ttrain-auc:0.984167\n",
      "[182]\ttrain-auc:0.984188\n",
      "[183]\ttrain-auc:0.984202\n",
      "[184]\ttrain-auc:0.984225\n",
      "[185]\ttrain-auc:0.984234\n",
      "[186]\ttrain-auc:0.984258\n",
      "[187]\ttrain-auc:0.984306\n",
      "[188]\ttrain-auc:0.984311\n",
      "[189]\ttrain-auc:0.984316\n",
      "[190]\ttrain-auc:0.984324\n",
      "[191]\ttrain-auc:0.984352\n",
      "[192]\ttrain-auc:0.984369\n",
      "[193]\ttrain-auc:0.984385\n",
      "[194]\ttrain-auc:0.984407\n",
      "[195]\ttrain-auc:0.984421\n",
      "[196]\ttrain-auc:0.98443\n",
      "[197]\ttrain-auc:0.984438\n",
      "[198]\ttrain-auc:0.984448\n",
      "[199]\ttrain-auc:0.98445\n",
      "[200]\ttrain-auc:0.984461\n",
      "[201]\ttrain-auc:0.984466\n",
      "[202]\ttrain-auc:0.984502\n",
      "[203]\ttrain-auc:0.984504\n",
      "[204]\ttrain-auc:0.984507\n",
      "[205]\ttrain-auc:0.984519\n",
      "[206]\ttrain-auc:0.98454\n",
      "[207]\ttrain-auc:0.98459\n",
      "[208]\ttrain-auc:0.984588\n",
      "[209]\ttrain-auc:0.984594\n",
      "[210]\ttrain-auc:0.984592\n",
      "[211]\ttrain-auc:0.984606\n",
      "[212]\ttrain-auc:0.984608\n",
      "[213]\ttrain-auc:0.984613\n",
      "[214]\ttrain-auc:0.984618\n",
      "[215]\ttrain-auc:0.984622\n",
      "[216]\ttrain-auc:0.98464\n",
      "[217]\ttrain-auc:0.984643\n",
      "[218]\ttrain-auc:0.984652\n",
      "[219]\ttrain-auc:0.984657\n",
      "[220]\ttrain-auc:0.984671\n",
      "[221]\ttrain-auc:0.984677\n",
      "[222]\ttrain-auc:0.984696\n",
      "[223]\ttrain-auc:0.984701\n",
      "[224]\ttrain-auc:0.984707\n",
      "[225]\ttrain-auc:0.984757\n",
      "[226]\ttrain-auc:0.984769\n",
      "[227]\ttrain-auc:0.984783\n",
      "[228]\ttrain-auc:0.984791\n",
      "[229]\ttrain-auc:0.984799\n",
      "[230]\ttrain-auc:0.984812\n",
      "[231]\ttrain-auc:0.98482\n",
      "[232]\ttrain-auc:0.984821\n",
      "[233]\ttrain-auc:0.984822\n",
      "[234]\ttrain-auc:0.984836\n",
      "[235]\ttrain-auc:0.984843\n",
      "[236]\ttrain-auc:0.984852\n",
      "[237]\ttrain-auc:0.984858\n",
      "[238]\ttrain-auc:0.984865\n",
      "[239]\ttrain-auc:0.984873\n",
      "[240]\ttrain-auc:0.984872\n",
      "[241]\ttrain-auc:0.984877\n",
      "[242]\ttrain-auc:0.984886\n",
      "[243]\ttrain-auc:0.984891\n",
      "[244]\ttrain-auc:0.984898\n",
      "[245]\ttrain-auc:0.984905\n",
      "[246]\ttrain-auc:0.984918\n",
      "[247]\ttrain-auc:0.984926\n",
      "[248]\ttrain-auc:0.984933\n",
      "[249]\ttrain-auc:0.984939\n",
      "[250]\ttrain-auc:0.984945\n",
      "[251]\ttrain-auc:0.984944\n",
      "[252]\ttrain-auc:0.984942\n",
      "[253]\ttrain-auc:0.984944\n",
      "[254]\ttrain-auc:0.984949\n",
      "[255]\ttrain-auc:0.984957\n",
      "[256]\ttrain-auc:0.984973\n",
      "[257]\ttrain-auc:0.984981\n",
      "[258]\ttrain-auc:0.984985\n",
      "[259]\ttrain-auc:0.984991\n",
      "[260]\ttrain-auc:0.984999\n",
      "[261]\ttrain-auc:0.985006\n",
      "[262]\ttrain-auc:0.985018\n",
      "[263]\ttrain-auc:0.985033\n",
      "[264]\ttrain-auc:0.985038\n",
      "[265]\ttrain-auc:0.985043\n",
      "[266]\ttrain-auc:0.985046\n",
      "[267]\ttrain-auc:0.985053\n",
      "[268]\ttrain-auc:0.985066\n",
      "[269]\ttrain-auc:0.98507\n",
      "[270]\ttrain-auc:0.985077\n",
      "[271]\ttrain-auc:0.985083\n",
      "[272]\ttrain-auc:0.985088\n",
      "[273]\ttrain-auc:0.985093\n",
      "[274]\ttrain-auc:0.985097\n",
      "[275]\ttrain-auc:0.985101\n",
      "[276]\ttrain-auc:0.985108\n",
      "[277]\ttrain-auc:0.985114\n",
      "[278]\ttrain-auc:0.985117\n",
      "[279]\ttrain-auc:0.985123\n",
      "[280]\ttrain-auc:0.985129\n",
      "[281]\ttrain-auc:0.985136\n",
      "[282]\ttrain-auc:0.985144\n",
      "[283]\ttrain-auc:0.985152\n",
      "[284]\ttrain-auc:0.985153\n",
      "[285]\ttrain-auc:0.985153\n",
      "[286]\ttrain-auc:0.985166\n",
      "[287]\ttrain-auc:0.985183\n",
      "[288]\ttrain-auc:0.985186\n",
      "[289]\ttrain-auc:0.985194\n",
      "[290]\ttrain-auc:0.985217\n",
      "[291]\ttrain-auc:0.985225\n",
      "[292]\ttrain-auc:0.98523\n",
      "[293]\ttrain-auc:0.985236\n",
      "[294]\ttrain-auc:0.985243\n",
      "[295]\ttrain-auc:0.985249\n",
      "[296]\ttrain-auc:0.985256\n",
      "[297]\ttrain-auc:0.985259\n",
      "[298]\ttrain-auc:0.985266\n",
      "[299]\ttrain-auc:0.985271\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train_all,label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_all)\n",
    "param = {'max_depth':20, 'eta':0.02, 'silent':1, 'objective':'binary:logistic',\n",
    "         'nthread':4, 'eval_metric':'auc', 'subsample':0.7, 'colsample_bytree':0.7,\n",
    "         'min_child_weight':0, 'booster':\"gbtree\"}\n",
    "\n",
    "watchlist  = [(dtrain,'train')]\n",
    "num_round = 300\n",
    "early_stopping_rounds=10\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist ,early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "ypred_xgboost = bst.predict(dtest)\n",
    "output_xgboost = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred_xgboost })\n",
    "output_xgboost.to_csv('result_xgboost2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.923607\n",
      "Will train until train-auc hasn't improved in 10 rounds.\n",
      "[1]\ttrain-auc:0.946671\n",
      "[2]\ttrain-auc:0.950223\n",
      "[3]\ttrain-auc:0.952621\n",
      "[4]\ttrain-auc:0.955183\n",
      "[5]\ttrain-auc:0.957566\n",
      "[6]\ttrain-auc:0.959072\n",
      "[7]\ttrain-auc:0.960026\n",
      "[8]\ttrain-auc:0.960406\n",
      "[9]\ttrain-auc:0.960223\n",
      "[10]\ttrain-auc:0.960696\n",
      "[11]\ttrain-auc:0.960602\n",
      "[12]\ttrain-auc:0.961769\n",
      "[13]\ttrain-auc:0.962151\n",
      "[14]\ttrain-auc:0.962659\n",
      "[15]\ttrain-auc:0.963063\n",
      "[16]\ttrain-auc:0.963105\n",
      "[17]\ttrain-auc:0.963227\n",
      "[18]\ttrain-auc:0.964142\n",
      "[19]\ttrain-auc:0.964232\n",
      "[20]\ttrain-auc:0.96434\n",
      "[21]\ttrain-auc:0.964362\n",
      "[22]\ttrain-auc:0.964562\n",
      "[23]\ttrain-auc:0.964682\n",
      "[24]\ttrain-auc:0.964927\n",
      "[25]\ttrain-auc:0.96496\n",
      "[26]\ttrain-auc:0.965177\n",
      "[27]\ttrain-auc:0.966816\n",
      "[28]\ttrain-auc:0.967245\n",
      "[29]\ttrain-auc:0.967304\n",
      "[30]\ttrain-auc:0.967317\n",
      "[31]\ttrain-auc:0.967469\n",
      "[32]\ttrain-auc:0.96773\n",
      "[33]\ttrain-auc:0.968238\n",
      "[34]\ttrain-auc:0.968462\n",
      "[35]\ttrain-auc:0.968793\n",
      "[36]\ttrain-auc:0.968843\n",
      "[37]\ttrain-auc:0.968854\n",
      "[38]\ttrain-auc:0.96895\n",
      "[39]\ttrain-auc:0.968981\n",
      "[40]\ttrain-auc:0.968968\n",
      "[41]\ttrain-auc:0.969059\n",
      "[42]\ttrain-auc:0.969255\n",
      "[43]\ttrain-auc:0.969984\n",
      "[44]\ttrain-auc:0.9702\n",
      "[45]\ttrain-auc:0.970217\n",
      "[46]\ttrain-auc:0.970381\n",
      "[47]\ttrain-auc:0.97069\n",
      "[48]\ttrain-auc:0.970653\n",
      "[49]\ttrain-auc:0.970717\n",
      "[50]\ttrain-auc:0.970896\n",
      "[51]\ttrain-auc:0.970902\n",
      "[52]\ttrain-auc:0.970987\n",
      "[53]\ttrain-auc:0.971061\n",
      "[54]\ttrain-auc:0.97143\n",
      "[55]\ttrain-auc:0.971612\n",
      "[56]\ttrain-auc:0.971719\n",
      "[57]\ttrain-auc:0.971976\n",
      "[58]\ttrain-auc:0.972033\n",
      "[59]\ttrain-auc:0.972082\n",
      "[60]\ttrain-auc:0.972257\n",
      "[61]\ttrain-auc:0.972511\n",
      "[62]\ttrain-auc:0.972799\n",
      "[63]\ttrain-auc:0.972982\n",
      "[64]\ttrain-auc:0.973131\n",
      "[65]\ttrain-auc:0.973195\n",
      "[66]\ttrain-auc:0.973382\n",
      "[67]\ttrain-auc:0.973428\n",
      "[68]\ttrain-auc:0.973661\n",
      "[69]\ttrain-auc:0.973731\n",
      "[70]\ttrain-auc:0.973801\n",
      "[71]\ttrain-auc:0.973948\n",
      "[72]\ttrain-auc:0.974022\n",
      "[73]\ttrain-auc:0.974066\n",
      "[74]\ttrain-auc:0.974263\n",
      "[75]\ttrain-auc:0.974482\n",
      "[76]\ttrain-auc:0.974584\n",
      "[77]\ttrain-auc:0.974695\n",
      "[78]\ttrain-auc:0.974834\n",
      "[79]\ttrain-auc:0.974993\n",
      "[80]\ttrain-auc:0.975097\n",
      "[81]\ttrain-auc:0.975252\n",
      "[82]\ttrain-auc:0.975348\n",
      "[83]\ttrain-auc:0.97548\n",
      "[84]\ttrain-auc:0.975719\n",
      "[85]\ttrain-auc:0.97589\n",
      "[86]\ttrain-auc:0.976204\n",
      "[87]\ttrain-auc:0.97642\n",
      "[88]\ttrain-auc:0.976666\n",
      "[89]\ttrain-auc:0.976781\n",
      "[90]\ttrain-auc:0.976996\n",
      "[91]\ttrain-auc:0.977216\n",
      "[92]\ttrain-auc:0.977375\n",
      "[93]\ttrain-auc:0.977509\n",
      "[94]\ttrain-auc:0.977658\n",
      "[95]\ttrain-auc:0.977911\n",
      "[96]\ttrain-auc:0.978132\n",
      "[97]\ttrain-auc:0.978179\n",
      "[98]\ttrain-auc:0.978281\n",
      "[99]\ttrain-auc:0.978338\n",
      "[100]\ttrain-auc:0.978485\n",
      "[101]\ttrain-auc:0.978743\n",
      "[102]\ttrain-auc:0.978794\n",
      "[103]\ttrain-auc:0.978821\n",
      "[104]\ttrain-auc:0.978922\n",
      "[105]\ttrain-auc:0.978993\n",
      "[106]\ttrain-auc:0.979055\n",
      "[107]\ttrain-auc:0.97916\n",
      "[108]\ttrain-auc:0.979315\n",
      "[109]\ttrain-auc:0.979572\n",
      "[110]\ttrain-auc:0.979779\n",
      "[111]\ttrain-auc:0.979803\n",
      "[112]\ttrain-auc:0.980026\n",
      "[113]\ttrain-auc:0.9802\n",
      "[114]\ttrain-auc:0.980317\n",
      "[115]\ttrain-auc:0.980411\n",
      "[116]\ttrain-auc:0.980505\n",
      "[117]\ttrain-auc:0.980555\n",
      "[118]\ttrain-auc:0.980582\n",
      "[119]\ttrain-auc:0.980702\n",
      "[120]\ttrain-auc:0.980778\n",
      "[121]\ttrain-auc:0.980873\n",
      "[122]\ttrain-auc:0.981016\n",
      "[123]\ttrain-auc:0.981148\n",
      "[124]\ttrain-auc:0.981221\n",
      "[125]\ttrain-auc:0.981319\n",
      "[126]\ttrain-auc:0.981486\n",
      "[127]\ttrain-auc:0.981569\n",
      "[128]\ttrain-auc:0.981623\n",
      "[129]\ttrain-auc:0.981683\n",
      "[130]\ttrain-auc:0.981794\n",
      "[131]\ttrain-auc:0.981869\n",
      "[132]\ttrain-auc:0.981874\n",
      "[133]\ttrain-auc:0.981956\n",
      "[134]\ttrain-auc:0.981977\n",
      "[135]\ttrain-auc:0.982091\n",
      "[136]\ttrain-auc:0.982106\n",
      "[137]\ttrain-auc:0.982185\n",
      "[138]\ttrain-auc:0.9823\n",
      "[139]\ttrain-auc:0.982319\n",
      "[140]\ttrain-auc:0.982471\n",
      "[141]\ttrain-auc:0.98251\n",
      "[142]\ttrain-auc:0.982724\n",
      "[143]\ttrain-auc:0.982737\n",
      "[144]\ttrain-auc:0.982779\n",
      "[145]\ttrain-auc:0.982887\n",
      "[146]\ttrain-auc:0.982944\n",
      "[147]\ttrain-auc:0.983098\n",
      "[148]\ttrain-auc:0.983124\n",
      "[149]\ttrain-auc:0.983183\n",
      "[150]\ttrain-auc:0.983227\n",
      "[151]\ttrain-auc:0.983333\n",
      "[152]\ttrain-auc:0.983438\n",
      "[153]\ttrain-auc:0.983442\n",
      "[154]\ttrain-auc:0.983459\n",
      "[155]\ttrain-auc:0.983512\n",
      "[156]\ttrain-auc:0.98354\n",
      "[157]\ttrain-auc:0.983554\n",
      "[158]\ttrain-auc:0.983675\n",
      "[159]\ttrain-auc:0.983677\n",
      "[160]\ttrain-auc:0.983736\n",
      "[161]\ttrain-auc:0.983738\n",
      "[162]\ttrain-auc:0.983798\n",
      "[163]\ttrain-auc:0.983822\n",
      "[164]\ttrain-auc:0.983859\n",
      "[165]\ttrain-auc:0.983866\n",
      "[166]\ttrain-auc:0.983917\n",
      "[167]\ttrain-auc:0.98394\n",
      "[168]\ttrain-auc:0.98399\n",
      "[169]\ttrain-auc:0.983994\n",
      "[170]\ttrain-auc:0.984012\n",
      "[171]\ttrain-auc:0.98403\n",
      "[172]\ttrain-auc:0.984069\n",
      "[173]\ttrain-auc:0.984105\n",
      "[174]\ttrain-auc:0.984114\n",
      "[175]\ttrain-auc:0.984154\n",
      "[176]\ttrain-auc:0.984173\n",
      "[177]\ttrain-auc:0.984247\n",
      "[178]\ttrain-auc:0.984267\n",
      "[179]\ttrain-auc:0.984294\n",
      "[180]\ttrain-auc:0.984391\n",
      "[181]\ttrain-auc:0.984392\n",
      "[182]\ttrain-auc:0.984398\n",
      "[183]\ttrain-auc:0.984409\n",
      "[184]\ttrain-auc:0.984422\n",
      "[185]\ttrain-auc:0.984433\n",
      "[186]\ttrain-auc:0.984443\n",
      "[187]\ttrain-auc:0.984461\n",
      "[188]\ttrain-auc:0.984462\n",
      "[189]\ttrain-auc:0.984469\n",
      "[190]\ttrain-auc:0.984496\n",
      "[191]\ttrain-auc:0.9845\n",
      "[192]\ttrain-auc:0.984513\n",
      "[193]\ttrain-auc:0.984517\n",
      "[194]\ttrain-auc:0.984544\n",
      "[195]\ttrain-auc:0.984548\n",
      "[196]\ttrain-auc:0.984573\n",
      "[197]\ttrain-auc:0.984578\n",
      "[198]\ttrain-auc:0.984585\n",
      "[199]\ttrain-auc:0.984584\n",
      "[200]\ttrain-auc:0.984597\n",
      "[201]\ttrain-auc:0.984599\n",
      "[202]\ttrain-auc:0.984616\n",
      "[203]\ttrain-auc:0.984623\n",
      "[204]\ttrain-auc:0.984634\n",
      "[205]\ttrain-auc:0.984641\n",
      "[206]\ttrain-auc:0.984659\n",
      "[207]\ttrain-auc:0.984697\n",
      "[208]\ttrain-auc:0.984703\n",
      "[209]\ttrain-auc:0.984708\n",
      "[210]\ttrain-auc:0.984714\n",
      "[211]\ttrain-auc:0.984717\n",
      "[212]\ttrain-auc:0.984723\n",
      "[213]\ttrain-auc:0.984728\n",
      "[214]\ttrain-auc:0.984735\n",
      "[215]\ttrain-auc:0.984739\n",
      "[216]\ttrain-auc:0.984783\n",
      "[217]\ttrain-auc:0.984788\n",
      "[218]\ttrain-auc:0.984793\n",
      "[219]\ttrain-auc:0.984797\n",
      "[220]\ttrain-auc:0.984806\n",
      "[221]\ttrain-auc:0.984812\n",
      "[222]\ttrain-auc:0.984818\n",
      "[223]\ttrain-auc:0.984822\n",
      "[224]\ttrain-auc:0.984828\n",
      "[225]\ttrain-auc:0.984864\n",
      "[226]\ttrain-auc:0.984863\n",
      "[227]\ttrain-auc:0.984872\n",
      "[228]\ttrain-auc:0.984881\n",
      "[229]\ttrain-auc:0.984892\n",
      "[230]\ttrain-auc:0.984897\n",
      "[231]\ttrain-auc:0.984891\n",
      "[232]\ttrain-auc:0.984892\n",
      "[233]\ttrain-auc:0.984899\n",
      "[234]\ttrain-auc:0.984911\n",
      "[235]\ttrain-auc:0.984916\n",
      "[236]\ttrain-auc:0.984924\n",
      "[237]\ttrain-auc:0.984933\n",
      "[238]\ttrain-auc:0.984943\n",
      "[239]\ttrain-auc:0.984953\n",
      "[240]\ttrain-auc:0.984952\n",
      "[241]\ttrain-auc:0.984954\n",
      "[242]\ttrain-auc:0.984961\n",
      "[243]\ttrain-auc:0.984968\n",
      "[244]\ttrain-auc:0.984974\n",
      "[245]\ttrain-auc:0.984981\n",
      "[246]\ttrain-auc:0.984992\n",
      "[247]\ttrain-auc:0.984998\n",
      "[248]\ttrain-auc:0.985009\n",
      "[249]\ttrain-auc:0.985014\n",
      "[250]\ttrain-auc:0.985011\n",
      "[251]\ttrain-auc:0.985017\n",
      "[252]\ttrain-auc:0.985026\n",
      "[253]\ttrain-auc:0.985032\n",
      "[254]\ttrain-auc:0.985039\n",
      "[255]\ttrain-auc:0.985048\n",
      "[256]\ttrain-auc:0.985054\n",
      "[257]\ttrain-auc:0.985061\n",
      "[258]\ttrain-auc:0.985073\n",
      "[259]\ttrain-auc:0.985078\n",
      "[260]\ttrain-auc:0.985085\n",
      "[261]\ttrain-auc:0.98509\n",
      "[262]\ttrain-auc:0.9851\n",
      "[263]\ttrain-auc:0.98511\n",
      "[264]\ttrain-auc:0.985113\n",
      "[265]\ttrain-auc:0.985117\n",
      "[266]\ttrain-auc:0.985121\n",
      "[267]\ttrain-auc:0.985128\n",
      "[268]\ttrain-auc:0.98513\n",
      "[269]\ttrain-auc:0.985136\n",
      "[270]\ttrain-auc:0.985142\n",
      "[271]\ttrain-auc:0.98515\n",
      "[272]\ttrain-auc:0.985159\n",
      "[273]\ttrain-auc:0.985167\n",
      "[274]\ttrain-auc:0.985174\n",
      "[275]\ttrain-auc:0.985179\n",
      "[276]\ttrain-auc:0.985184\n",
      "[277]\ttrain-auc:0.985183\n",
      "[278]\ttrain-auc:0.985187\n",
      "[279]\ttrain-auc:0.985192\n",
      "[280]\ttrain-auc:0.9852\n",
      "[281]\ttrain-auc:0.985222\n",
      "[282]\ttrain-auc:0.985229\n",
      "[283]\ttrain-auc:0.985235\n",
      "[284]\ttrain-auc:0.985238\n",
      "[285]\ttrain-auc:0.985243\n",
      "[286]\ttrain-auc:0.985271\n",
      "[287]\ttrain-auc:0.985292\n",
      "[288]\ttrain-auc:0.985298\n",
      "[289]\ttrain-auc:0.985304\n",
      "[290]\ttrain-auc:0.985321\n",
      "[291]\ttrain-auc:0.985328\n",
      "[292]\ttrain-auc:0.985331\n",
      "[293]\ttrain-auc:0.985336\n",
      "[294]\ttrain-auc:0.985334\n",
      "[295]\ttrain-auc:0.985342\n",
      "[296]\ttrain-auc:0.98535\n",
      "[297]\ttrain-auc:0.985356\n",
      "[298]\ttrain-auc:0.985365\n",
      "[299]\ttrain-auc:0.98537\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train_all,label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_all)\n",
    "param = {'max_depth':20, 'eta':0.02, 'silent':1, 'objective':'binary:logistic',\n",
    "         'nthread':4, 'eval_metric':'auc', 'subsample':0.75, 'colsample_bytree':0.75,\n",
    "         'min_child_weight':0, 'booster':\"gbtree\"}\n",
    "\n",
    "watchlist  = [(dtrain,'train')]\n",
    "num_round = 300\n",
    "early_stopping_rounds=10\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist ,early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "ypred_xgboost = bst.predict(dtest)\n",
    "output_xgboost = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred_xgboost })\n",
    "output_xgboost.to_csv('result_xgboost3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.89192\n",
      "Will train until train-auc hasn't improved in 15 rounds.\n",
      "[1]\ttrain-auc:0.900562\n",
      "[2]\ttrain-auc:0.909177\n",
      "[3]\ttrain-auc:0.917468\n",
      "[4]\ttrain-auc:0.925206\n",
      "[5]\ttrain-auc:0.932294\n",
      "[6]\ttrain-auc:0.938923\n",
      "[7]\ttrain-auc:0.945178\n",
      "[8]\ttrain-auc:0.951067\n",
      "[9]\ttrain-auc:0.956569\n",
      "[10]\ttrain-auc:0.961622\n",
      "[11]\ttrain-auc:0.966171\n",
      "[12]\ttrain-auc:0.970196\n",
      "[13]\ttrain-auc:0.973708\n",
      "[14]\ttrain-auc:0.976735\n",
      "[15]\ttrain-auc:0.979315\n",
      "[16]\ttrain-auc:0.981501\n",
      "[17]\ttrain-auc:0.983343\n",
      "[18]\ttrain-auc:0.984893\n",
      "[19]\ttrain-auc:0.986192\n",
      "[20]\ttrain-auc:0.987287\n",
      "[21]\ttrain-auc:0.988213\n",
      "[22]\ttrain-auc:0.989003\n",
      "[23]\ttrain-auc:0.989683\n",
      "[24]\ttrain-auc:0.990276\n",
      "[25]\ttrain-auc:0.990798\n",
      "[26]\ttrain-auc:0.991263\n",
      "[27]\ttrain-auc:0.991677\n",
      "[28]\ttrain-auc:0.99205\n",
      "[29]\ttrain-auc:0.992387\n",
      "[30]\ttrain-auc:0.992694\n",
      "[31]\ttrain-auc:0.992975\n",
      "[32]\ttrain-auc:0.993234\n",
      "[33]\ttrain-auc:0.993471\n",
      "[34]\ttrain-auc:0.99369\n",
      "[35]\ttrain-auc:0.993892\n",
      "[36]\ttrain-auc:0.994079\n",
      "[37]\ttrain-auc:0.994254\n",
      "[38]\ttrain-auc:0.994416\n",
      "[39]\ttrain-auc:0.994568\n",
      "[40]\ttrain-auc:0.99471\n",
      "[41]\ttrain-auc:0.994843\n",
      "[42]\ttrain-auc:0.994968\n",
      "[43]\ttrain-auc:0.995086\n",
      "[44]\ttrain-auc:0.995197\n",
      "[45]\ttrain-auc:0.995302\n",
      "[46]\ttrain-auc:0.995401\n",
      "[47]\ttrain-auc:0.995494\n",
      "[48]\ttrain-auc:0.995582\n",
      "[49]\ttrain-auc:0.995666\n",
      "[50]\ttrain-auc:0.995746\n",
      "[51]\ttrain-auc:0.995821\n",
      "[52]\ttrain-auc:0.995893\n",
      "[53]\ttrain-auc:0.995961\n",
      "[54]\ttrain-auc:0.996026\n",
      "[55]\ttrain-auc:0.996087\n",
      "[56]\ttrain-auc:0.996146\n",
      "[57]\ttrain-auc:0.996201\n",
      "[58]\ttrain-auc:0.996254\n",
      "[59]\ttrain-auc:0.996305\n",
      "[60]\ttrain-auc:0.996353\n",
      "[61]\ttrain-auc:0.996399\n",
      "[62]\ttrain-auc:0.996443\n",
      "[63]\ttrain-auc:0.996485\n",
      "[64]\ttrain-auc:0.996525\n",
      "[65]\ttrain-auc:0.996563\n",
      "[66]\ttrain-auc:0.9966\n",
      "[67]\ttrain-auc:0.996635\n",
      "[68]\ttrain-auc:0.996668\n",
      "[69]\ttrain-auc:0.996701\n",
      "[70]\ttrain-auc:0.996731\n",
      "[71]\ttrain-auc:0.996761\n",
      "[72]\ttrain-auc:0.996789\n",
      "[73]\ttrain-auc:0.996816\n",
      "[74]\ttrain-auc:0.996842\n",
      "[75]\ttrain-auc:0.996867\n",
      "[76]\ttrain-auc:0.996891\n",
      "[77]\ttrain-auc:0.996914\n",
      "[78]\ttrain-auc:0.996936\n",
      "[79]\ttrain-auc:0.996957\n",
      "[80]\ttrain-auc:0.996977\n",
      "[81]\ttrain-auc:0.996997\n",
      "[82]\ttrain-auc:0.997015\n",
      "[83]\ttrain-auc:0.997033\n",
      "[84]\ttrain-auc:0.99705\n",
      "[85]\ttrain-auc:0.997067\n",
      "[86]\ttrain-auc:0.997083\n",
      "[87]\ttrain-auc:0.997098\n",
      "[88]\ttrain-auc:0.997113\n",
      "[89]\ttrain-auc:0.997127\n",
      "[90]\ttrain-auc:0.99714\n",
      "[91]\ttrain-auc:0.997154\n",
      "[92]\ttrain-auc:0.997166\n",
      "[93]\ttrain-auc:0.997178\n",
      "[94]\ttrain-auc:0.99719\n",
      "[95]\ttrain-auc:0.997201\n",
      "[96]\ttrain-auc:0.997211\n",
      "[97]\ttrain-auc:0.997222\n",
      "[98]\ttrain-auc:0.997231\n",
      "[99]\ttrain-auc:0.997241\n",
      "[100]\ttrain-auc:0.99725\n",
      "[101]\ttrain-auc:0.997259\n",
      "[102]\ttrain-auc:0.997268\n",
      "[103]\ttrain-auc:0.997276\n",
      "[104]\ttrain-auc:0.997284\n",
      "[105]\ttrain-auc:0.997292\n",
      "[106]\ttrain-auc:0.997299\n",
      "[107]\ttrain-auc:0.997306\n",
      "[108]\ttrain-auc:0.997313\n",
      "[109]\ttrain-auc:0.99732\n",
      "[110]\ttrain-auc:0.997327\n",
      "[111]\ttrain-auc:0.997333\n",
      "[112]\ttrain-auc:0.997339\n",
      "[113]\ttrain-auc:0.997345\n",
      "[114]\ttrain-auc:0.997351\n",
      "[115]\ttrain-auc:0.997356\n",
      "[116]\ttrain-auc:0.997362\n",
      "[117]\ttrain-auc:0.997367\n",
      "[118]\ttrain-auc:0.997372\n",
      "[119]\ttrain-auc:0.997377\n",
      "[120]\ttrain-auc:0.997382\n",
      "[121]\ttrain-auc:0.997387\n",
      "[122]\ttrain-auc:0.997392\n",
      "[123]\ttrain-auc:0.997396\n",
      "[124]\ttrain-auc:0.997401\n",
      "[125]\ttrain-auc:0.997405\n",
      "[126]\ttrain-auc:0.997409\n",
      "[127]\ttrain-auc:0.997413\n",
      "[128]\ttrain-auc:0.997417\n",
      "[129]\ttrain-auc:0.997421\n",
      "[130]\ttrain-auc:0.997425\n",
      "[131]\ttrain-auc:0.997429\n",
      "[132]\ttrain-auc:0.997432\n",
      "[133]\ttrain-auc:0.997436\n",
      "[134]\ttrain-auc:0.997439\n",
      "[135]\ttrain-auc:0.997443\n",
      "[136]\ttrain-auc:0.997446\n",
      "[137]\ttrain-auc:0.997449\n",
      "[138]\ttrain-auc:0.997453\n",
      "[139]\ttrain-auc:0.997456\n",
      "[140]\ttrain-auc:0.997459\n",
      "[141]\ttrain-auc:0.997462\n",
      "[142]\ttrain-auc:0.997465\n",
      "[143]\ttrain-auc:0.997468\n",
      "[144]\ttrain-auc:0.99747\n",
      "[145]\ttrain-auc:0.997473\n",
      "[146]\ttrain-auc:0.997476\n",
      "[147]\ttrain-auc:0.997478\n",
      "[148]\ttrain-auc:0.997481\n",
      "[149]\ttrain-auc:0.997484\n",
      "[150]\ttrain-auc:0.997486\n",
      "[151]\ttrain-auc:0.997489\n",
      "[152]\ttrain-auc:0.997491\n",
      "[153]\ttrain-auc:0.997493\n",
      "[154]\ttrain-auc:0.997496\n",
      "[155]\ttrain-auc:0.997498\n",
      "[156]\ttrain-auc:0.9975\n",
      "[157]\ttrain-auc:0.997502\n",
      "[158]\ttrain-auc:0.997504\n",
      "[159]\ttrain-auc:0.997506\n",
      "[160]\ttrain-auc:0.997508\n",
      "[161]\ttrain-auc:0.99751\n",
      "[162]\ttrain-auc:0.997512\n",
      "[163]\ttrain-auc:0.997514\n",
      "[164]\ttrain-auc:0.997516\n",
      "[165]\ttrain-auc:0.997518\n",
      "[166]\ttrain-auc:0.99752\n",
      "[167]\ttrain-auc:0.997522\n",
      "[168]\ttrain-auc:0.997523\n",
      "[169]\ttrain-auc:0.997525\n",
      "[170]\ttrain-auc:0.997527\n",
      "[171]\ttrain-auc:0.997528\n",
      "[172]\ttrain-auc:0.99753\n",
      "[173]\ttrain-auc:0.997532\n",
      "[174]\ttrain-auc:0.997533\n",
      "[175]\ttrain-auc:0.997535\n",
      "[176]\ttrain-auc:0.997536\n",
      "[177]\ttrain-auc:0.997538\n",
      "[178]\ttrain-auc:0.997539\n",
      "[179]\ttrain-auc:0.997541\n",
      "[180]\ttrain-auc:0.997542\n",
      "[181]\ttrain-auc:0.997543\n",
      "[182]\ttrain-auc:0.997545\n",
      "[183]\ttrain-auc:0.997546\n",
      "[184]\ttrain-auc:0.997547\n",
      "[185]\ttrain-auc:0.997549\n",
      "[186]\ttrain-auc:0.99755\n",
      "[187]\ttrain-auc:0.997551\n",
      "[188]\ttrain-auc:0.997553\n",
      "[189]\ttrain-auc:0.997554\n",
      "[190]\ttrain-auc:0.997555\n",
      "[191]\ttrain-auc:0.997556\n",
      "[192]\ttrain-auc:0.997557\n",
      "[193]\ttrain-auc:0.997558\n",
      "[194]\ttrain-auc:0.99756\n",
      "[195]\ttrain-auc:0.997561\n",
      "[196]\ttrain-auc:0.997562\n",
      "[197]\ttrain-auc:0.997563\n",
      "[198]\ttrain-auc:0.997564\n",
      "[199]\ttrain-auc:0.997565\n",
      "[200]\ttrain-auc:0.997566\n",
      "[201]\ttrain-auc:0.997567\n",
      "[202]\ttrain-auc:0.997568\n",
      "[203]\ttrain-auc:0.997569\n",
      "[204]\ttrain-auc:0.99757\n",
      "[205]\ttrain-auc:0.997571\n",
      "[206]\ttrain-auc:0.997572\n",
      "[207]\ttrain-auc:0.997573\n",
      "[208]\ttrain-auc:0.997574\n",
      "[209]\ttrain-auc:0.997575\n",
      "[210]\ttrain-auc:0.997576\n",
      "[211]\ttrain-auc:0.997576\n",
      "[212]\ttrain-auc:0.997577\n",
      "[213]\ttrain-auc:0.997578\n",
      "[214]\ttrain-auc:0.997579\n",
      "[215]\ttrain-auc:0.99758\n",
      "[216]\ttrain-auc:0.997581\n",
      "[217]\ttrain-auc:0.997582\n",
      "[218]\ttrain-auc:0.997582\n",
      "[219]\ttrain-auc:0.997583\n",
      "[220]\ttrain-auc:0.997584\n",
      "[221]\ttrain-auc:0.997585\n",
      "[222]\ttrain-auc:0.997586\n",
      "[223]\ttrain-auc:0.997586\n",
      "[224]\ttrain-auc:0.997587\n",
      "[225]\ttrain-auc:0.997588\n",
      "[226]\ttrain-auc:0.997589\n",
      "[227]\ttrain-auc:0.997589\n",
      "[228]\ttrain-auc:0.99759\n",
      "[229]\ttrain-auc:0.997591\n",
      "[230]\ttrain-auc:0.997591\n",
      "[231]\ttrain-auc:0.997592\n",
      "[232]\ttrain-auc:0.997593\n",
      "[233]\ttrain-auc:0.997594\n",
      "[234]\ttrain-auc:0.997594\n",
      "[235]\ttrain-auc:0.997595\n",
      "[236]\ttrain-auc:0.997595\n",
      "[237]\ttrain-auc:0.997596\n",
      "[238]\ttrain-auc:0.997597\n",
      "[239]\ttrain-auc:0.997597\n",
      "[240]\ttrain-auc:0.997598\n",
      "[241]\ttrain-auc:0.997599\n",
      "[242]\ttrain-auc:0.997599\n",
      "[243]\ttrain-auc:0.9976\n",
      "[244]\ttrain-auc:0.997601\n",
      "[245]\ttrain-auc:0.997601\n",
      "[246]\ttrain-auc:0.997602\n",
      "[247]\ttrain-auc:0.997602\n",
      "[248]\ttrain-auc:0.997603\n",
      "[249]\ttrain-auc:0.997604\n",
      "[250]\ttrain-auc:0.997604\n",
      "[251]\ttrain-auc:0.997605\n",
      "[252]\ttrain-auc:0.997605\n",
      "[253]\ttrain-auc:0.997606\n",
      "[254]\ttrain-auc:0.997606\n",
      "[255]\ttrain-auc:0.997607\n",
      "[256]\ttrain-auc:0.997607\n",
      "[257]\ttrain-auc:0.997608\n",
      "[258]\ttrain-auc:0.997608\n",
      "[259]\ttrain-auc:0.997609\n",
      "[260]\ttrain-auc:0.997609\n",
      "[261]\ttrain-auc:0.99761\n",
      "[262]\ttrain-auc:0.99761\n",
      "[263]\ttrain-auc:0.997611\n",
      "[264]\ttrain-auc:0.997611\n",
      "[265]\ttrain-auc:0.997612\n",
      "[266]\ttrain-auc:0.997612\n",
      "[267]\ttrain-auc:0.997613\n",
      "[268]\ttrain-auc:0.997613\n",
      "[269]\ttrain-auc:0.997614\n",
      "[270]\ttrain-auc:0.997614\n",
      "[271]\ttrain-auc:0.997615\n",
      "[272]\ttrain-auc:0.997615\n",
      "[273]\ttrain-auc:0.997616\n",
      "[274]\ttrain-auc:0.997616\n",
      "[275]\ttrain-auc:0.997616\n",
      "[276]\ttrain-auc:0.997617\n",
      "[277]\ttrain-auc:0.997617\n",
      "[278]\ttrain-auc:0.997618\n",
      "[279]\ttrain-auc:0.997618\n",
      "[280]\ttrain-auc:0.997619\n",
      "[281]\ttrain-auc:0.997619\n",
      "[282]\ttrain-auc:0.997619\n",
      "[283]\ttrain-auc:0.99762\n",
      "[284]\ttrain-auc:0.99762\n",
      "[285]\ttrain-auc:0.997621\n",
      "[286]\ttrain-auc:0.997621\n",
      "[287]\ttrain-auc:0.997621\n",
      "[288]\ttrain-auc:0.997622\n",
      "[289]\ttrain-auc:0.997622\n",
      "[290]\ttrain-auc:0.997622\n",
      "[291]\ttrain-auc:0.997623\n",
      "[292]\ttrain-auc:0.997623\n",
      "[293]\ttrain-auc:0.997624\n",
      "[294]\ttrain-auc:0.997624\n",
      "[295]\ttrain-auc:0.997624\n",
      "[296]\ttrain-auc:0.997625\n",
      "[297]\ttrain-auc:0.997625\n",
      "[298]\ttrain-auc:0.997625\n",
      "[299]\ttrain-auc:0.997626\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train_all,label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_all)\n",
    "\n",
    "param = {'max_depth':20, 'eta':0.02, 'silent':1, 'objective':'binary:logistic',\n",
    "         'nthread':-1, 'eval_metric':'auc', 'subsample':0.75, 'colsample_bytree':0.75,\n",
    "         'min_child_weight':0, 'booster':\"gblinear\"}\n",
    "\n",
    "watchlist  = [(dtrain,'train')]\n",
    "num_round = 300\n",
    "early_stopping_rounds = 15\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist ,early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "ypred_xgboost = bst.predict(dtest)\n",
    "output_xgboost = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred_xgboost })\n",
    "output_xgboost.to_csv('result_xgboost4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# KNN\n",
    "# Logistics Regression\n",
    "# SGD Regression\n",
    "# Adaboost\n",
    "# Bagging\n",
    "# Gradient Boosting\n",
    "# RandomForest\n",
    "# Deep Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # KNN taking too long for sparse matrix\n",
    "# # KNN fit\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# knn = KNeighborsRegressor(n_neighbors=5, n_jobs=-1)\n",
    "# knn.fit(X_train_all, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # KNN predict\n",
    "# ypred_knn = knn.predict(X_test_all)\n",
    "# ypred_knn = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred_knn })\n",
    "# ypred_knn.to_csv('result_knn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=5, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistics Regression fit\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor\n",
    "logreg = LogisticRegression(C=1e5, verbose=5)\n",
    "logreg.fit(X_train_all, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logistics Regression predict\n",
    "ypred_logreg = logreg.predict(X_test_all)\n",
    "ypred_logreg = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred_logreg })\n",
    "ypred_logreg.to_csv('result_logreg.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 763.52, NNZs: 31604, Bias: -0.023258, T: 2197291, Avg. loss: 20576.356453\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 608.07, NNZs: 33881, Bias: -0.023205, T: 4394582, Avg. loss: 11106.347728\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 544.77, NNZs: 34775, Bias: -0.023239, T: 6591873, Avg. loss: 7715.185509\n",
      "Total training time: 2.28 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 498.18, NNZs: 35257, Bias: -0.023265, T: 8789164, Avg. loss: 5948.849123\n",
      "Total training time: 3.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 469.18, NNZs: 35579, Bias: -0.023267, T: 10986455, Avg. loss: 4858.916162\n",
      "Total training time: 3.81 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 445.98, NNZs: 35806, Bias: -0.023277, T: 13183746, Avg. loss: 4116.448675\n",
      "Total training time: 4.56 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 426.76, NNZs: 35994, Bias: -0.023283, T: 15381037, Avg. loss: 3576.655968\n",
      "Total training time: 5.32 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 411.85, NNZs: 36119, Bias: -0.023290, T: 17578328, Avg. loss: 3165.894116\n",
      "Total training time: 6.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 398.89, NNZs: 36217, Bias: -0.023301, T: 19775619, Avg. loss: 2842.373729\n",
      "Total training time: 6.96 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 387.07, NNZs: 36309, Bias: -0.023307, T: 21972910, Avg. loss: 2580.752948\n",
      "Total training time: 7.68 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=10, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(verbose=1, n_iter=10, loss='log')\n",
    "sgd.fit(X_train_all, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # SGD predict\n",
    "ypred_sgd = sgd.predict(X_test_all)\n",
    "ypred_sgd = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred_sgd })\n",
    "ypred_sgd.to_csv('result_sgd.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best'),\n",
       "         learning_rate=1.0, loss='linear', n_estimators=100,\n",
       "         random_state=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaboost fit \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "adaboost = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), n_estimators=100)\n",
    "adaboost.fit(X_train_all, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adaboost predict \n",
    "ypred_adaboost = adaboost.predict(X_test_all)\n",
    "ypred_adaboost = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred_adaboost })\n",
    "ypred_adaboost.to_csv('result_adaboost.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RandomForest fit (too long for sparse matrix)\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# random_forest = RandomForestRegressor(n_estimators=10, max_depth=100,\n",
    "#                                       n_jobs=-1, verbose=2)\n",
    "# random_forest.fit(X_train_all, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RandomForest predict\n",
    "# ypred_random_forest = random_forest.predict(X_test_all)\n",
    "# ypred_random_forest = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred_random_forest })\n",
    "# ypred_random_forest.to_csv('result_random_forest.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2438           69.59m\n",
      "         2           0.2408           60.70m\n",
      "         3           0.2379           58.06m\n",
      "         4           0.2350           56.13m\n",
      "         5           0.2322           54.79m\n",
      "         6           0.2294           53.39m\n",
      "         7           0.2267           51.85m\n",
      "         8           0.2241           51.08m\n",
      "         9           0.2215           50.12m\n",
      "        10           0.2189           49.19m\n",
      "        20           0.1959           43.06m\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting fit\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "params = {'n_estimators': 100, 'max_depth': 10,\n",
    "          'learning_rate': 0.01, 'loss': 'ls', 'verbose':1}\n",
    "gradient_boosting = GradientBoostingRegressor(**params)\n",
    "gradient_boosting.fit(X_train_all, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting predict\n",
    "ypred_gradient_boosting = gradient_boosting.predict(X_test_all)\n",
    "ypred_gradient_boosting = pd.DataFrame({ 'activity_id' : X_test_all['activity_id'], 'outcome': ypred_gradient_boosting })\n",
    "ypred_gradient_boosting.to_csv('result_gradient_boosting.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Neural Net fit (too large the dimension for keras)\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# import numpy\n",
    "# dnn = Sequential()\n",
    "# dnn.add(Dense(80000, input_dim=41532, init='uniform', activation='relu'))\n",
    "# dnn.add(Dense(10000, init='uniform', activation='relu'))\n",
    "# dnn.add(Dense(1000, init='uniform', activation='relu'))\n",
    "# dnn.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "# dnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# dnn.fit(X_train_all, y_train, nb_epoch=150, batch_size=10,  verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Deep Neural Net predict\n",
    "# # calculate predictions\n",
    "# ypred_dnn = dnn.predict(X_test_all)\n",
    "# # round predictions\n",
    "# ypred_dnn_rounded = [round(x[0]) for x in ypred_dnn]\n",
    "# ypred_dnn_rounded = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred_dnn_rounded })\n",
    "# ypred_dnn_rounded.to_csv('result_dnn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # SVM polynomial fit (large data cannot run finish)\n",
    "# from sklearn.svm import SVR\n",
    "# svr_poly = SVR(kernel='poly', C=1e3, degree=3)\n",
    "# svr_poly.fit(X_train_all, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # SVM polynomial train\n",
    "# ypred_svr_poly = svr_poly.predict(X_test_all)\n",
    "# ypred_svr_poly = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred_svr_poly })\n",
    "# ypred_svr_poly.to_csv('result_svr_poly.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-1f384765d2eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred_gnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred_gnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m'activity_id'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activity_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outcome'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_pred_gnb\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuu/dev/anaconda3/envs/redhat/lib/python3.6/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuu/dev/anaconda3/envs/redhat/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1007\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Naive Bayes (not enough memory)\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# gnb = GaussianNB()\n",
    "# gnb.fit(X_train_all.toarray(), y_train)\n",
    "# y_pred_gnb = gnb.predict(X_test_all)\n",
    "# y_pred_gnb = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': y_pred_gnb })\n",
    "# y_pred_gnb.to_csv('result_gnb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
